{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOTaiUC8m6cwiSJrpEwn3lz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HoneyBohra26/Fashion-Forward-MNIST-Model-Optimization-and-Deployment/blob/main/Fashion_mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "diFdO9YjY2XN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38126113-ab29-47d1-8d0f-eb9d5f0c7591"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: hyperopt in /usr/local/lib/python3.10/dist-packages (0.2.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from hyperopt) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from hyperopt) (1.11.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from hyperopt) (1.16.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from hyperopt) (3.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from hyperopt) (0.18.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from hyperopt) (4.66.4)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from hyperopt) (2.2.1)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (from hyperopt) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "pip install hyperopt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VIt93hkLaLVH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7636e127-7aea-4da7-8674-735383b05418"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mlflow in /usr/local/lib/python3.10/dist-packages (2.14.3)\n",
            "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.2.5)\n",
            "Requirement already satisfied: alembic!=1.10.0,<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.13.2)\n",
            "Requirement already satisfied: cachetools<6,>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (5.4.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (8.1.7)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.2.1)\n",
            "Requirement already satisfied: docker<8,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (7.1.0)\n",
            "Requirement already satisfied: entrypoints<1 in /usr/local/lib/python3.10/dist-packages (from mlflow) (0.4)\n",
            "Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.1.43)\n",
            "Requirement already satisfied: graphene<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.3)\n",
            "Requirement already satisfied: importlib-metadata!=4.7.0,<8,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (7.1.0)\n",
            "Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.6)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.7.1)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.25.2)\n",
            "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.25.0)\n",
            "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.25.0)\n",
            "Requirement already satisfied: packaging<25 in /usr/local/lib/python3.10/dist-packages (from mlflow) (24.1)\n",
            "Requirement already satisfied: pandas<3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.0.3)\n",
            "Requirement already satisfied: protobuf<5,>=3.12.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.20.3)\n",
            "Requirement already satisfied: pyarrow<16,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (14.0.2)\n",
            "Requirement already satisfied: pytz<2025 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2023.4)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.10/dist-packages (from mlflow) (6.0.1)\n",
            "Requirement already satisfied: querystring-parser<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.2.4)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.31.0)\n",
            "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.2.2)\n",
            "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.10/dist-packages (from mlflow) (1.11.4)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (2.0.31)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow) (0.5.1)\n",
            "Requirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.10/dist-packages (from mlflow) (3.1.4)\n",
            "Requirement already satisfied: gunicorn<23 in /usr/local/lib/python3.10/dist-packages (from mlflow) (22.0.0)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic!=1.10.0,<2->mlflow) (1.3.5)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic!=1.10.0,<2->mlflow) (4.12.2)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from docker<8,>=4.0.0->mlflow) (2.0.7)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow) (3.0.3)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow) (2.2.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython<4,>=3.1.9->mlflow) (4.0.11)\n",
            "Requirement already satisfied: graphql-core<3.3,>=3.1 in /usr/local/lib/python3.10/dist-packages (from graphene<4->mlflow) (3.2.3)\n",
            "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /usr/local/lib/python3.10/dist-packages (from graphene<4->mlflow) (3.2.0)\n",
            "Requirement already satisfied: aniso8601<10,>=8 in /usr/local/lib/python3.10/dist-packages (from graphene<4->mlflow) (9.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata!=4.7.0,<8,>=3.7.0->mlflow) (3.19.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2<4,>=2.11->mlflow) (2.1.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow) (2.8.2)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow) (1.2.14)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.46b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow) (0.46b0)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3->mlflow) (2024.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from querystring-parser<2->mlflow) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow) (3.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow) (2024.7.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2->mlflow) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2->mlflow) (3.5.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.0.3)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow) (1.14.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow) (5.0.1)\n"
          ]
        }
      ],
      "source": [
        "pip install mlflow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iypOVxPXa0-i"
      },
      "outputs": [],
      "source": [
        "import mlflow\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t3ssJik8bdKr"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "puGSBal_bdH3"
      },
      "outputs": [],
      "source": [
        "train_set = torchvision.datasets.FashionMNIST(\"./data\", download=True, transform=\n",
        "                                                transforms.Compose([transforms.ToTensor()]))\n",
        "test_set = torchvision.datasets.FashionMNIST(\"./data\", download=True, train=False, transform=\n",
        "                                               transforms.Compose([transforms.ToTensor() ]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KzZRRN59bdFP"
      },
      "outputs": [],
      "source": [
        "batch_size = 100\n",
        "train_loader = torch.utils.data.DataLoader(train_set,\n",
        "                                           batch_size=batch_size)\n",
        "test_loader = torch.utils.data.DataLoader(test_set,\n",
        "                                          batch_size=batch_size)\n",
        "\n",
        "train_loss_list = []\n",
        "train_accuracy_list = []\n",
        "\n",
        "test_loss_list = []\n",
        "test_accuracy_list = []\n",
        "global best_test_accuracy\n",
        "best_test_accuracy = 0"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2aPrjBy1d2mZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBlLGxZBbdB7"
      },
      "outputs": [],
      "source": [
        "def output_label(label):\n",
        "    output_mapping = {\n",
        "                 0: \"T-shirt/Top\",\n",
        "                 1: \"Trouser\",\n",
        "                 2: \"Pullover\",\n",
        "                 3: \"Dress\",\n",
        "                 4: \"Coat\",\n",
        "                 5: \"Sandal\",\n",
        "                 6: \"Shirt\",\n",
        "                 7: \"Sneaker\",\n",
        "                 8: \"Bag\",\n",
        "                 9: \"Ankle Boot\"\n",
        "                 }\n",
        "    input = (label.item() if type(label) == torch.Tensor else label)\n",
        "    return output_mapping[input]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CrKKNCiFbc_h"
      },
      "outputs": [],
      "source": [
        "class FashionCNN(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(FashionCNN, self).__init__()\n",
        "\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2)\n",
        "        )\n",
        "\n",
        "        self.fc1 = nn.Linear(in_features=64*6*6, out_features=600)\n",
        "        self.drop = nn.Dropout(0.25)\n",
        "        self.fc2 = nn.Linear(in_features=600, out_features=120)\n",
        "        self.fc3 = nn.Linear(in_features=120, out_features=10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.fc1(out)\n",
        "        out = self.drop(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.fc3(out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oN7iXpM3qICG"
      },
      "outputs": [],
      "source": [
        "def validate_model(model,test_loader,checkpoint_dir,epoch,best_test_accuracy):\n",
        "\n",
        "      error = nn.CrossEntropyLoss()\n",
        "\n",
        "      labels_list2 = []\n",
        "      predictions_list2 = []\n",
        "      correct = 0\n",
        "      total2 = 0\n",
        "      running_loss2 = 0\n",
        "\n",
        "      with torch.inference_mode():\n",
        "\n",
        "        for images, labels in test_loader:\n",
        "          images, labels = images.to(device), labels.to(device)\n",
        "          labels_list2.append(labels)\n",
        "\n",
        "          if images.shape[1] == 1:\n",
        "            images = images.repeat(1, 3, 1, 1)  # Repeat the grayscale channel 3 times\n",
        "\n",
        "          test = (images.view(100, 3,28, 28))\n",
        "\n",
        "          outputs = model(test)\n",
        "          loss = error(outputs, labels)\n",
        "          running_loss2 += loss.item() * images.size(0)\n",
        "\n",
        "          predictions = torch.max(outputs, 1)[1].to(device)\n",
        "          predictions_list2.append(predictions)\n",
        "          correct += (predictions == labels).sum()\n",
        "\n",
        "          total2 += len(labels)\n",
        "\n",
        "        labels_cpu2 = torch.cat(labels_list2).cpu().numpy() # Move to CPU and convert to NumPy\n",
        "        predictionss_cpu2 = torch.cat(predictions_list2).cpu().numpy() # Move to CPU and convert to NumPy\n",
        "\n",
        "\n",
        "        test_accuracy = accuracy_score(labels_cpu2, predictionss_cpu2)\n",
        "        test_loss = running_loss2 / total2\n",
        "        print(\"Test_Loss: {},Test_Accuracy: {}%\".format(test_loss, test_accuracy))\n",
        "        mlflow.log_metrics({\"Test_Accuracy\": float(test_accuracy), \"Test_Loss\": float(test_loss)})\n",
        "\n",
        "        # Save model checkpoint if test accuracy improves\n",
        "        if test_accuracy > best_test_accuracy:\n",
        "            best_test_accuracy = test_accuracy\n",
        "            checkpoint_path = os.path.join(checkpoint_dir, f'model_epoch_{epoch + 1}.pth')\n",
        "            torch.save(model.state_dict(), checkpoint_path)\n",
        "            print(f'Model checkpoint saved at {checkpoint_path}')\n",
        "\n",
        "        test_loss_list.append(test_loss)\n",
        "        test_accuracy_list.append(test_accuracy)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3hJKQ55e3Tvd"
      },
      "outputs": [],
      "source": [
        "def log_model_n_params(model,labels_list,predictions_list,params):\n",
        "\n",
        "    labels_cpu = torch.cat(labels_list).cpu().numpy() # Move to CPU and convert to NumPy\n",
        "    predictionss_cpu = torch.cat(predictions_list).cpu().numpy() # Move to CPU and convert to NumPy\n",
        "\n",
        "    mlflow.pytorch.log_model(\n",
        "    pytorch_model=model,\n",
        "    artifact_path=\"model1\",\n",
        "    signature=None,\n",
        "    registered_model_name=\"model1\",)\n",
        "\n",
        "    # Log confusion matrix (example assuming you convert it to JSON)\n",
        "    cm = confusion_matrix(labels_cpu, predictionss_cpu)\n",
        "    cm_json = {'confusion_matrix': cm.tolist()}  # Convert to JSON or other suitable format\n",
        "    mlflow.log_param('confusion_matrix', cm_json)\n",
        "\n",
        "    # Log parameters\n",
        "    mlflow.log_params(params)\n",
        "\n",
        "    # plot and log confusion matrix\n",
        "    plt.figure(figsize=(12, 12))\n",
        "    sns.heatmap(cm_json['confusion_matrix'], annot=True, cmap='coolwarm', square=True)\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.show()\n",
        "    plt.savefig('confusion_matrix.png')\n",
        "    mlflow.log_artifact('confusion_matrix.png')\n",
        "\n",
        "    print(cm_json.keys())\n",
        "    print(cm_json['confusion_matrix'])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q-rP6xcg7cF8"
      },
      "outputs": [],
      "source": [
        "def evaluation_metrics_n_Hyperparameters(labels_list,predictions_list,train_loss,epoch):\n",
        "      # Calculate evaluation metrics\n",
        "      labels_cpu = torch.cat(labels_list).cpu().numpy() # Move to CPU and convert to NumPy\n",
        "      predictionss_cpu = torch.cat(predictions_list).cpu().numpy() # Move to CPU and convert to NumPy\n",
        "\n",
        "\n",
        "      accuracy = accuracy_score(labels_cpu, predictionss_cpu)\n",
        "      precision = precision_score(labels_cpu, predictionss_cpu, average='macro')\n",
        "      recall = recall_score(labels_cpu, predictionss_cpu, average='macro')\n",
        "\n",
        "      # Log metrics\n",
        "\n",
        "      mlflow.log_metric('accuracy', accuracy)\n",
        "      mlflow.log_metric('precision', precision)\n",
        "      mlflow.log_metric('recall', recall)\n",
        "      mlflow.log_metric('loss', train_loss)\n",
        "\n",
        "      print(\"epoch: {}, Loss: {}, Accuracy: {}%\".format(epoch, train_loss, accuracy))\n",
        "\n",
        "      train_loss_list.append(train_loss)\n",
        "      train_accuracy_list.append(accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8DS7Qlno2RSz"
      },
      "outputs": [],
      "source": [
        "def plot_loss_accuracy(train_loss_list, train_accuracy_list, test_loss_list, test_accuracy_list,num_epochs):\n",
        "\n",
        "    epochs = range(0, num_epochs )\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs, train_loss_list, 'b', label='Training Loss')\n",
        "    plt.plot(epochs, test_loss_list, 'r', label='Test Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.title('Training and Test Loss')\n",
        "    plt.savefig('Training and Test Loss.png')\n",
        "    mlflow.log_artifact('Training and Test Loss.png')\n",
        "\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs, train_accuracy_list, 'b', label='Training Accuracy')\n",
        "    plt.plot(epochs, test_accuracy_list, 'r', label='Test Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.title('Training and Test Accuracy')\n",
        "    plt.savefig('Training and Test Accuracy.png')\n",
        "    mlflow.log_artifact('Training and Test Accuracy.png')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N3vDV2r0mKAT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xw-_-4IZbc8x"
      },
      "outputs": [],
      "source": [
        "def train_model(model,train_loader,params,scheduler):\n",
        "\n",
        "    # hyperparameters\n",
        "    learning_rate = params['learning_rate']\n",
        "    num_epochs = int(params['num_epochs'])\n",
        "    optimizer = params['optimizer']\n",
        "    batch_size = int(params['batch_size'])\n",
        "    error = nn.CrossEntropyLoss()\n",
        "\n",
        "    if optimizer_name == 'Adam':\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    elif optimizer_name == 'SGD':\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    count = 0\n",
        "    # Lists for knowing classwise accuracy\n",
        "    predictions_list = []\n",
        "    labels_list = []\n",
        "\n",
        "    running_loss = 0\n",
        "    total = 0\n",
        "\n",
        "    # Directory to save model checkpoints\n",
        "    checkpoint_dir = 'checkpoints'\n",
        "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "      for images, labels in train_loader:\n",
        "\n",
        "          # Transfering images and labels to GPU if available\n",
        "          images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "          if images.shape[1] == 1:\n",
        "           images = images.repeat(1, 3, 1, 1)  # Repeat the grayscale channel 3 times\n",
        "\n",
        "          train = (images.view(100, 3, 28, 28))\n",
        "          labels = (labels)\n",
        "\n",
        "\n",
        "          # Forward pass\n",
        "          outputs = model(train)\n",
        "          loss = error(outputs, labels)\n",
        "          running_loss += loss.item() * images.size(0)\n",
        "          predictions = torch.max(outputs, 1)[1].to(device)\n",
        "          predictions_list.append(predictions)\n",
        "          labels_list.append(labels)\n",
        "\n",
        "          # Initializing a gradient as 0 so there is no mixing of gradient among the batches\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          #Propagating the error backward\n",
        "          loss.backward()\n",
        "\n",
        "          # Optimizing the parameters\n",
        "          optimizer.step()\n",
        "\n",
        "          # Total\n",
        "          total += len(labels)\n",
        "\n",
        "      # loss calculation\n",
        "      train_loss = running_loss / total\n",
        "\n",
        "      scheduler.step()  # Update learning rate\n",
        "\n",
        "      # validation\n",
        "      validate_model(model,test_loader,checkpoint_dir,epoch,best_test_accuracy)\n",
        "\n",
        "      #logging and evaluating metrics_n_Hyperparameters\n",
        "      evaluation_metrics_n_Hyperparameters(labels_list,predictions_list,train_loss,epoch)\n",
        "\n",
        "    #logging the model\n",
        "    log_model_n_params(model,labels_list,predictions_list,params)\n",
        "    #plotting loss and accuracy\n",
        "    plot_loss_accuracy(train_loss_list, train_accuracy_list, test_loss_list, test_accuracy_list,num_epochs)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7ytK25-Mbc3K"
      },
      "outputs": [],
      "source": [
        "def objective(params):\n",
        "    \"\"\"Objective function for hyperparameter optimization.\"\"\"\n",
        "    learning_rate = params['learning_rate']\n",
        "    num_epochs = int(params['num_epochs'])\n",
        "    optimizer_name = params['optimizer']\n",
        "    batch_size = int(params['batch_size'])\n",
        "\n",
        "    count = 0\n",
        "    # Lists for knowing classwise accuracy\n",
        "    predictions_list = []\n",
        "    labels_list = []\n",
        "\n",
        "    running_loss = 0\n",
        "    total = 0\n",
        "\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "      for images, labels in train_loader:\n",
        "\n",
        "          # Transfering images and labels to GPU if available\n",
        "          images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "          if images.shape[1] == 1:\n",
        "           images = images.repeat(1, 3, 1, 1)  # Repeat the grayscale channel 3 times\n",
        "\n",
        "          train = (images.view(100, 3, 28, 28))\n",
        "          labels = (labels)\n",
        "\n",
        "\n",
        "          # Forward pass\n",
        "          outputs = model(train)\n",
        "          loss = error(outputs, labels)\n",
        "          running_loss += loss.item() * images.size(0)\n",
        "          predictions = torch.max(outputs, 1)[1].to(device)\n",
        "          predictions_list.append(predictions)\n",
        "          labels_list.append(labels)\n",
        "\n",
        "          # Initializing a gradient as 0 so there is no mixing of gradient among the batches\n",
        "          optimizer.zero_grad()\n",
        "\n",
        "          #Propagating the error backward\n",
        "          loss.backward()\n",
        "\n",
        "          # Optimizing the parameters\n",
        "          optimizer.step()\n",
        "\n",
        "          # Total\n",
        "          total += len(labels)\n",
        "\n",
        "      # loss calculation\n",
        "      train_loss = running_loss / total\n",
        "\n",
        "      scheduler.step()  # Update learning rate\n",
        "\n",
        "    # validation\n",
        "    labels_list2 = []\n",
        "    predictions_list2 = []\n",
        "    correct = 0\n",
        "    total2 = 0\n",
        "    running_loss2 = 0\n",
        "\n",
        "    with torch.inference_mode():\n",
        "\n",
        "      for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        labels_list2.append(labels)\n",
        "\n",
        "        if images.shape[1] == 1:\n",
        "          images = images.repeat(1, 3, 1, 1)  # Repeat the grayscale channel 3 times\n",
        "\n",
        "        test = (images.view(100, 3,28, 28))\n",
        "\n",
        "        outputs = model(test)\n",
        "        loss = error(outputs, labels)\n",
        "        running_loss2 += loss.item() * images.size(0)\n",
        "\n",
        "        predictions = torch.max(outputs, 1)[1].to(device)\n",
        "        predictions_list2.append(predictions)\n",
        "        correct += (predictions == labels).sum()\n",
        "\n",
        "        total2 += len(labels)\n",
        "\n",
        "      labels_cpu2 = torch.cat(labels_list2).cpu().numpy() # Move to CPU and convert to NumPy\n",
        "      predictionss_cpu2 = torch.cat(predictions_list2).cpu().numpy() # Move to CPU and convert to NumPy\n",
        "\n",
        "\n",
        "      val_accuracy = accuracy_score(labels_cpu2, predictionss_cpu2)\n",
        "      val_loss = running_loss2 / total2\n",
        "\n",
        "    return {'loss': val_loss, 'status': STATUS_OK}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YSRXpf1Wbc0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "outputId": "7dce079a-c8b0-4bd5-e7a4-dd57864c0fc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100%|██████████| 2/2 [01:01<00:00, 30.65s/trial, best loss: 0.29014128014445306]\n",
            "Best hyperparameters: {'batch_size': 1, 'learning_rate': 0.01681145159632138, 'num_epochs': 2.0, 'optimizer': 0}\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'numpy.int64' object has no attribute 'zero_grad'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-537f27b0376e>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best hyperparameters:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbest_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;31m#   model_conv = torchvision.models.resnet18(pretrained=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-77c563876859>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, params, scheduler)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m           \u001b[0;31m# Initializing a gradient as 0 so there is no mixing of gradient among the batches\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m           \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m           \u001b[0;31m#Propagating the error backward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.int64' object has no attribute 'zero_grad'"
          ]
        }
      ],
      "source": [
        "mlflow.set_experiment(\"MNIST_fashion model_resnet\")\n",
        "\n",
        "with mlflow.start_run() as run:\n",
        "\n",
        "\n",
        "  model = torchvision.models.resnet18(pretrained=True)\n",
        "  num_ftrs = model.fc.in_features\n",
        "\n",
        "  model.fc = nn.Linear(num_ftrs, 10)\n",
        "\n",
        "  model = model.to(device)\n",
        "\n",
        "  # error = nn.CrossEntropyLoss()\n",
        "  # learning_rate = 0.001\n",
        "  # optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "  # scheduler = StepLR(optimizer, step_size=3, gamma=0.1)  # Decay LR by a factor of 0.1 every 3 epochs\n",
        "  # num_epochs = 6\n",
        "\n",
        "#   params = {\n",
        "#     \"learning_rate\": learning_rate,\n",
        "#     \"num_epochs\": num_epochs,\n",
        "#     \"optimizer\": optimizer,\n",
        "#     \"batch_size\": batch_size,\n",
        "#     \"Activation\" : \"ReLU\",\n",
        "#     \"Loss_Function\" : error\n",
        "# }\n",
        "\n",
        "  # Define the search space for hyperparameters\n",
        "  search_space = {\n",
        "        'learning_rate': hp.loguniform('learning_rate', -6, -1),\n",
        "        'num_epochs': hp.quniform('num_epochs', 1, 3, 1),\n",
        "        'optimizer': hp.choice('optimizer', ['Adam', 'SGD']),\n",
        "        'batch_size': hp.choice('batch_size', [32, 64, 128]),\n",
        "    }\n",
        "\n",
        "  # Initialize Trials object to store results\n",
        "  trials = Trials()\n",
        "\n",
        "    # Run hyperparameter optimization\n",
        "  best_params = fmin(\n",
        "      fn=objective,\n",
        "      space=search_space,\n",
        "      algo=tpe.suggest,\n",
        "      max_evals=1,  # Number of evaluations to run\n",
        "      trials=trials,\n",
        "  )\n",
        "\n",
        "  print(\"Best hyperparameters:\", best_params)\n",
        "\n",
        "  model =  train_model(model,train_loader,best_params,scheduler)\n",
        "\n",
        "#   model_conv = torchvision.models.resnet18(pretrained=True)\n",
        "#   for param in model_conv.parameters():\n",
        "#       param.requires_grad = False\n",
        "\n",
        "#   num_ftrs = model_conv.fc.in_features\n",
        "#   model_conv.fc = nn.Linear(num_ftrs, 10)\n",
        "\n",
        "#   model_conv = model_conv.to(device)\n",
        "\n",
        "#   model_conv =  train_model(model_conv,train_loader)\n",
        "\n",
        "mlflow.end_run()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_tkm_pEQYf_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AM_B1pGZbc5y"
      },
      "outputs": [],
      "source": [
        "# with mlflow.start_run() as run:\n",
        "\n",
        "#   model = FashionCNN()\n",
        "#   model.to(device)\n",
        "\n",
        "#   error = nn.CrossEntropyLoss()\n",
        "\n",
        "#   learning_rate = 0.001\n",
        "#   optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "#   num_epochs = 10\n",
        "#   count = 0\n",
        "#   # Lists for visualization of loss and accuracy\n",
        "#   loss_list = []\n",
        "#   iteration_list = []\n",
        "#   accuracy_list = []\n",
        "\n",
        "#   # Lists for knowing classwise accuracy\n",
        "#   predictions_list = []\n",
        "#   labels_list = []\n",
        "\n",
        "#   for epoch in range(num_epochs):\n",
        "#     for images, labels in train_loader:\n",
        "#         # Transfering images and labels to GPU if available\n",
        "#         images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "#         train = Variable(images.view(100, 1, 224, 224))\n",
        "#         labels = Variable(labels)\n",
        "\n",
        "#         # Forward pass\n",
        "#         outputs = model(train)\n",
        "#         loss = error(outputs, labels)\n",
        "\n",
        "#         # Initializing a gradient as 0 so there is no mixing of gradient among the batches\n",
        "#         optimizer.zero_grad()\n",
        "\n",
        "#         #Propagating the error backward\n",
        "#         loss.backward()\n",
        "\n",
        "#         # Optimizing the parameters\n",
        "#         optimizer.step()\n",
        "\n",
        "#         count += 1\n",
        "#         # Testing the model\n",
        "#         with torch.inference_mode():\n",
        "\n",
        "#           if not (count % 50):    # It's same as \"if count % 50 == 0\"\n",
        "#               total = 0\n",
        "#               correct = 0\n",
        "\n",
        "#               for images, labels in test_loader:\n",
        "#                   images, labels = images.to(device), labels.to(device)\n",
        "#                   labels_list.append(labels)\n",
        "\n",
        "#                   test = Variable(images.view(100, 1,224, 224))\n",
        "\n",
        "#                   outputs = model(test)\n",
        "\n",
        "#                   predictions = torch.max(outputs, 1)[1].to(device)\n",
        "#                   predictions_list.append(predictions)\n",
        "#                   correct += (predictions == labels).sum()\n",
        "\n",
        "#                   total += len(labels)\n",
        "\n",
        "\n",
        "\n",
        "#               accuracy = correct * 100 / total\n",
        "#               loss_list.append(loss.data)\n",
        "#               iteration_list.append(count)\n",
        "#               accuracy_list.append(accuracy)\n",
        "\n",
        "\n",
        "\n",
        "#           if not (count % 500):\n",
        "#               print(\"Iteration: {}, Loss: {}, Accuracy: {}%\".format(count, loss.data, accuracy))\n",
        "#               mlflow.log_metrics({\"accuracy\": float(accuracy), \"loss\": float(loss.data)})\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#   mlflow.pytorch.log_model(\n",
        "#     pytorch_model=model,\n",
        "#     artifact_path=\"model1\",\n",
        "#     signature=None,\n",
        "#     registered_model_name=\"model1\",\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eySPHZA9bcxp"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v6CTzjA0bcvJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zCFLC_Wfbcqr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_8r6vaTjbcl3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cNkaeZwnbcjE"
      },
      "outputs": [],
      "source": []
    }
  ]
}